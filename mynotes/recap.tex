\labeledsection{Foundations}{sec:recap}
\subsection{Mathematical Language}
\definition{Natural Language}{
A natural language is any form of spoken or signed means of communication that has evolved naturally in humans through use and repetition without conscious planning or premeditation.
}{natural_language}

\definition{Domain of Discourse}{
The \linkterm{set}{def:set} of entities, objects, or concepts that a language, discussion, or formal system refers to. It specifies the scope within which terms, statements, and reasoning apply.  
}{domain_of_discourse}

\definition{Jargon (Terminology)}{
    A jargon (or terminology) is a \linkterm{set}{def:set} of specialized words or phrases (called technical terms or just terms) relating to concepts from a particular \linkterm{domain of discourse}{domain_of_discourse}.
}{terminology}


\definition{Technical Language}{
A technical language is a \linkterm{natural language}{natural_language} extended by a \linkterm{terminology}{terminology} and (possibly) special idioms, discourse markers, and notations.  
}{technical_language}

\definition{Stylized Language}{
Mathematicians use a stylized language that uses formulae to represent mathematical objects, uses math idioms for special situations (e.g. "iff", "hence", "let... be..., then..."), and classifies statements by role (e.g., definition, Lemma, Theorem, Proof, Example).
}{stylized_language}

\definition{Mathematical Vernacular}{
Specialized \linkterm{technical language}{technical_language} used by mathematicians to express definitions, proofs, and reasoning.  
It combines natural language, standard mathematical idioms, and symbolic expressions into a coherent style for clear mathematical communication.
}{mathematical_vernacular}



\definition{Formulae}{
    A mathematical formula can be a \refterm{mathematical statement}{math_statement} (clause) which can be true or false (e.g. $x>5, 3+5=7$), or a \refterm{mathematical object}{math_object} (e.g. $3, n, x^2 + y^2 + z^2, \int_1^0 x^{3/2} dx$)
}{formulae}

\definition{Sequence}{
    \linkterm{mathematical vernacular}{mathematical_vernacular} uses the concept of sequences instead of lists. Sequences are usually finite, but can be infinite as well.
}{sequence}

\definition{Ellipses}{
    \linkterm{mathematical vernacular}{mathematical_vernacular} uses ellipses ($\cdots$) as a constructor for \linkterm{sequences}{sequence}. The meaning of an ellipsis is usually considered "obvious" and left for interpretation by the reader.

\linkterm{ellipses}{ellipses} allow to write down large \linkterm{objects}{math_object} easily, examples:
\begin{itemize}
    \item $1, \cdots, n \leadsto$ the \linkterm{sequence}{sequence} of natural numbers between 1 and $n$ in order.
    \item $1, 4, 9, 16, \cdots \leadsto$ the \linkterm{sequence}{sequence} of squares in orders.
    \item $e_1, \cdots, e_n \leadsto$ a \linkterm{sequence}{sequence} of \linkterm{objects}{math_object} $e_i$ for $1 \leq i \leq n$
\end{itemize}
}{ellipses}

\definition{Varieties of Mathematical Statements}{
\linkterm{Mathematical statements}{math_statement} come in different epistemic varieties:
\begin{itemize}
    \item \refterm{Definitions}{definitions}: \linkterm{statements}{math_statement} that introduce new global identifier for important \linkterm{objects}{math_object}
    \item \refterm{Assertions}{assertions}: \linkterm{statements}{math_statement} that state properties of \linkterm{mathematical objects}{math_object}
    \item \refterm{Examples}{examples}: \linkterm{statements}{math_statement} that exhibit a witness for some property
    \item \refterm{Axioms}{axiom}: \linkterm{statements}{math_statement} that characterize the \linkterm{objects}{math_object} of a certain \linkterm{domain of discourse}{domain_of_discourse} or theory. An axiom (postulate) is a statement about \linkterm{mathematical objects}{math_object} that we \textit{assume} to be true.
\end{itemize}
}{varieties_math_statements}

\definition{Pragmatic Categories of Mathematical Assertions}{
\linkterm{Mathematical assertions}{assertions} are pragmatically classified into categories:
\begin{itemize}
    \item \refterm{proofs}{proofs} are arguments that justify the truth of \linkterm{statements}{math_statement} beyond any doubt. \linkterm{Proofs}{proofs} are not really \linkterm{statements}{math_statement}, but we sometimes treat them together.
    \item \refterm{proposition}{proposition} is a \linkterm{statement}{math_statement} which is interesting in its own right.
    \item \refterm{lemma}{lemma} is an easily proved \linkterm{statement}{math_statement} which is helpful for proving other \linkterm{propositions}{proposition} and \linkterm{theorems}{theorem}, but is usually not particularly interesting in its own right. A \linkterm{lemma}{lemma} is an intermediate \linkterm{theorem}{theorem} that serves as part of a \linkterm{proof}{proofs} of a larger \linkterm{theorem}{theorem}.
    \item \refterm{theorem}{theorem} is a more important \linkterm{statement}{math_statement} than a \linkterm{proposition}{proposition} which says something definitive on the subject, and often takes more effort to prove than a \linkterm{proposition}{proposition} or \linkterm{lemma}{lemma}. A \linkterm{theorem}{theorem} is a \linkterm{statement}{math_statement} about \linkterm{mathematical object}{math_object} that we \textit{know} to be true.
    \item \refterm{corollary}{corollary} is a quick consequence of a \linkterm{proposition}{proposition} or \linkterm{theorem}{theorem} that was proven rececently. It is a \linkterm{theorem}{theorem} that follows directly from another \linkterm{theorem}{theorem}.
    \item \refterm{conjecture}{conjecture} is a \linkterm{statement}{math_statement} that is thought to be provable, but has not been yet. A \linkterm{conjecture}{conjecture} that is proven is a \linkterm{theorem}{theorem}
\end{itemize}
}{assertion_categories}

\definition{Declaration}{
    In \linkterm{mathematical vernacular}{mathematical_vernacular} we call a clause that introduce new identifiers together with some properties a declaration. For example $\text{Let } \epsilon, \delta > 0 \cdots$
}{declaration}

\definition{Scope}{
    The scope of an identifier is the part of an expression where the reference is valid; that is, where the identifier can be used to refer. In the other parts, the identifier may refer to a different entity, or to nothing at all (unbound)
}{scope}

\definition{Definiendum}{
    The definiendum is the symbol, expression, or term being introduced by a \linkterm{definition}{definitions}. It is the newly named \linkterm{object}{math_object} or concept.
}{defineiendum}

\definition{Definiens}{
    The definiens is the symbol, expression, or construction that specifies the meaning of the \linkterm{defineiendum}{defineiendum}. It explains what the \linkterm{defineiendum}{defineiendum} denotes.
}{definiens}

\definition{Simple Definition}{
A \textbf{simple definition} introduces a new name (the \linkterm{defineiendum}{defineiendum}) for an existing \linkterm{object}{math_object} or concept (the \linkterm{definiens}{definiens}).  
The defineiendum must be new and must not occur in the definiens.  
We write simple definitions using $:=$ or $=:$, for example $\phi := 2$.
}{simpledefinition}

\definition{Pattern Definition}{
A \textbf{pattern definition} introduces a new \linkterm{operator}{arithmetic} or \linkterm{relation}{relation} by applying it to distinct pattern variables $v_{1},\dots,v_{n}$.  
The \linkterm{definiens}{definiens} is an expression in these variables.  
Applying the operator to arguments $a_{1},\dots,a_{n}$ means substituting $v_{i}$ by $a_{i}$ in the definiens.  
We use $:=$ for operator definitions and $:\Leftrightarrow$ for relation definitions.  
Example:  
\[
A \cap B := \{x \mid x \in A \land x \in B\}.
\]
}{patterndefinition}

\definition{Implicit Definition}{
An \textbf{implicit definition} (definition by description) specifies a new name $n$ (the \linkterm{defineiendum}{defineiendum}) by giving a clause $A$ such that we can prove unique existence $\exists^{1} n.\, A$.  
If such a \linkterm{proof}{proofs} exists, $n$ is \textbf{well-defined}.  
Example: the empty set $\Phi$ is implicitly defined by $\forall x.\, x \notin \Phi$.  
Another example: the exponential function is the unique $f:\mathbb{R}\to\mathbb{R}$ satisfying $f'=f$ and $f(0)=1$.
}{implicitdefinition}


\definition{Example}{
An example $E$ is a \linkterm{mathematical statement}{math_statement} that consists of:
\begin{itemize}
\item symbol $p$ for the \refterm{exemplandum}{exemplandum} (plural: exemplanda): the property to be exemplified,
\item the \refterm{exemplans}{exemplans} (plural: exemplantia): an expression $A$ denoting a \linkterm{mathematical object}{math_object} that acts as witness object for the property $p$, and
\item (optionally) a \refterm{justification}{justification} of $E$, i.e. a \linkterm{proof}{proofs} $\pi$ that $p(A)$ holds in the current context.
\end{itemize}
}{def:example}

\definition{Counter Example}{
An \linkterm{example}{def:example} for the complement of the property $p$ where $\pi$ is a \linkterm{proof}{proofs} that $p(A)$ does not hold.
}{def:counterexample}

\definition{Running Example}{
An \linkterm{example}{def:example} that is recalled time and again during an argument, applying the newly discovered knowledge to it, presumably to show how things work.
}{def:running_example}

\commandnote{
An \linkterm{example}{def:example} (or even several) for a \linkterm{mathematical statement}{math_statement} $B$ do not constitute a \linkterm{proof}{proofs} for $B$. On the other hand, one \linkterm{counter example}{def:counterexample} for a \linkterm{mathematical statement}{math_statement} $B$ does show that $\neg B$ is true ($\exists x. \neg A \equiv \neg (\forall x.A)$). 
}

\definition{Proof by Contradiction}{
A \textbf{proof by contradiction} assumes the negation $\neg A$ of the claim $A$ and derives a contradiction from that assumption.  
Since $\neg A$ cannot be true, we infer $\neg\neg A$ and therefore $A$.
}{proof_by_contradiction}

\definition{Proof by Local Hypothesis}{
A \textbf{proof by local hypothesis} is a proof of an implication $A \to B$ where we temporarily assume $A$ and derive $B$ from that assumption.  
After the subproof is closed, the assumption $A$ may no longer be used.
}{proof_by_local_hypothesis}

\definition{Chaining}{
\textbf{Chaining} applies a general implication $A \to B$ to a specific instance $A'$ obtained from $A$ by substituting variables with concrete values.  
This allows us to conclude the corresponding instance $B'$ obtained from $B$ by the same substitution.
}{chaining}

\definition{Without Loss of Generality (WLOG)}{
An \linkterm{inference}{def:inference} principle used in \linkterm{proofs}{proofs} when a \linkterm{statement}{math_statement} $Q(x)$ must be shown for all cases of $x$, but the different cases are equivalent by symmetry or trivial reduction.
\linkterm{Formally}{def:formal_logic}, if the domain of $x$ can be partitioned into cases $A_1, \dots, A_k$ and it can be shown that:
\begin{itemize}
\item proving $Q(x)$ under one representative case $A_i$ suffices, because
\item for every other case $A_j$ there is either a trivial \linkterm{proof}{proofs} of $Q(x)$ or a direct reduction to the representative case,
\end{itemize}
then we may assume $A_i$ holds ``without loss of generality''.  
This allows us to simplify the argument by only proving the representative case.
}{def:wlog}

\commandnote{
\textbf{WLOG Example.} if we want to prove the property $Q(p)$ for all primes $p$. We know that every prime is either $2$ (the only even prime) or an odd prime. If the case $p=2$ is easy, and the general odd prime case is the only real work, then we can say:
\begin{quote}
    \linkterm{WLOG}{def:wlog}, assume $p$ is odd
\end{quote}
This does not exclude the even case; it means we have already checked that the even case adds no new difficulty.
}

\definition{Greek Alphabet}{
In \linkterm{mathematical vernacular}{mathematical_vernacular}, Greek letters are used extensively to convey precise meanings. \Tabref{tab:greekalphabet} lists the Greek letters you are expected to recognize and write fluently.
}{def:greek_alphabet}

\commandnote{
In addition, \tabref{tab:roman_fraktur_letters} shows the curly Roman and Fraktur letters, which are also standard in mathematical writing.
}

\begin{table}[H]
\centering
\begin{tabular}{|c|c|c|c|c|c|c|c|c|}
\hline
$\alpha$ & $A$ & alpha   & $\beta$ & $B$ & beta   & $\gamma$ & $\Gamma$ & gamma \\ \hline
$\delta$ & $\Delta$ & delta   & $\epsilon$ & $E$ & epsilon & $\zeta$ & $Z$ & zeta \\ \hline
$\eta$   & $H$ & eta     & $\theta, \vartheta$ & $\Theta$ & theta & $\iota$ & $I$ & iota \\ \hline
$\kappa$ & $K$ & kappa   & $\lambda$ & $\Lambda$ & lambda & $\mu$ & $M$ & mu \\ \hline
$\nu$    & $N$ & nu      & $\xi$ & $\Xi$ & xi     & $o$ & $O$ & omicron \\ \hline
$\pi, \varpi$ & $\Pi$ & pi & $\rho$ & $P$ & rho   & $\sigma$ & $\Sigma$ & sigma \\ \hline
$\tau$   & $T$ & tau     & $\upsilon$ & $\Upsilon$ & upsilon & $\varphi, \phi$ & $\Phi$ & phi \\ \hline
$\chi$   & $X$ & chi     & $\psi$ & $\Psi$ & psi   & $\omega$ & $\Omega$ & omega \\ \hline
\end{tabular}
\caption{Greek Alphabet}
\label{tab:greekalphabet}
\end{table}

\begin{table}[H]
\centering
\begin{tabular}{|l|l|} \hline
Roman & $
\mathcal{A}, \mathcal{B}, \mathcal{C}, \mathcal{D}, \mathcal{E}, \mathcal{F}, 
\mathcal{G}, \mathcal{H}, \mathcal{I}, \mathcal{J}, \mathcal{K}, \mathcal{L}, 
\mathcal{M}, \mathcal{N}, \mathcal{O}, \mathcal{P}, \mathcal{Q}, \mathcal{R}, 
\mathcal{S}, \mathcal{T}, \mathcal{U}, \mathcal{V}, \mathcal{W}, \mathcal{X}, 
\mathcal{Y}, \mathcal{Z}
$ \\ \hline

Fraktur & $
\mathfrak{A}, \mathfrak{B}, \mathfrak{C}, \mathfrak{D}, \mathfrak{E}, \mathfrak{F}, 
\mathfrak{G}, \mathfrak{H}, \mathfrak{I}, \mathfrak{J}, \mathfrak{K}, \mathfrak{L}, 
\mathfrak{M}, \mathfrak{N}, \mathfrak{O}, \mathfrak{P}, \mathfrak{Q}, \mathfrak{R}, 
\mathfrak{S}, \mathfrak{T}, \mathfrak{U}, \mathfrak{V}, \mathfrak{W}, \mathfrak{X}, 
\mathfrak{Y}, \mathfrak{Z}
$ \\ \hline
\end{tabular}
\caption{Roman and Fraktur Letters}
\label{tab:roman_fraktur_letters}
\end{table}

\subsection{Sets}
\definition{Set}{
A collection of different things (called \textbf{elements} or \textbf{members} of the set). We can represent \linkterm{sets}{def:set} by listing the \linkterm{elements}{def:set} within curly brackets, e.g. $\set{a,b,c}$ or by describing the \linkterm{elements}{def:set} via a property, e.g. $\set{x \mid x \mod 2 = 0}$ (the \linkterm{set}{def:set} of even numbers). We can state \linkterm{element}{def:set}-hood ($a \in S$) or not ($b \notin S$)
}{def:set}

\definition{Set Equality}{
$A \equiv B : \equiv \forall x. x \in A \Leftrightarrow x \in B$
}{set_equality}

\definition{Subset}{
$A \subseteq B : \equiv \forall x.x \in A \Rightarrow x \in B$
}{subset}

\definition{Proper Subset}{
$A \subset B : \equiv (A \subseteq B) \land (A \not\equiv B)$
}{proper_subset}

\definition{Super Set}{
$A \supseteq B :\equiv \forall x.x \in B \Rightarrow x \in A$
}{superset}

\definition{Proper Superset}{
$A \supset B : \equiv (A \supseteq B) \land (A \not\equiv B)$
}{proper_superset}

\definition{Set Union}{
$A \cup B := \set{x \mid x \in A \lor x \in B}$
}{set_union}

\definition{Set Intersection}{
$A \cap B := \set{x \mid x \in A \land x \in B}$
}{set_intersection}

\definition{Disjoint}{
Two \linkterm{sets}{def:set} $A,B$ are \textbf{disjoint} iff $A \cap B = \Phi$
}{disjoint}

\definition{Set Difference}{
$A \setminus B := \set{x \mid x \in A \land x \notin B}$
}{set_difference}

\definition{Power Set}{
$\mathcal{P}(A) := \set{S \mid S \subseteq A}$ (the set of all subsets)
}{power_set}

\definition{Cartesian Product}{
$A \times B := \set{(a,b) \mid a \in A \land b \in B}, \quad (a,b) \text{ is a pair}$
}{cartesian_product}

\definition{Family}{
A \linkterm{set}{def:set} of \linkterm{sets}{def:set}
}{family}

\definition{Topology}{
A \linkterm{family}{family} of open \linkterm{sets}{def:set}
}{topology}

\definition{Indexing Function}{
Let $I$ and $X$ be \linkterm{sets}{def:set}. A function $f:I \to X$ is called an indexing function. The set $I$ is called the index set. For each $i \in I$, we define $x_i := f(i)$, here $i$ is called the index (or parameter) of $x_i$.
}{indexing_function}

\definition{Indexed Family}{
Given an \linkterm{indexing function}{indexing_function} $f:I \to X$, the \linkterm{set}{def:set} of values $f(I) = \set{f(i):i \in I}$ is called an indexed \linkterm{family}{family}. It is often written as $(x_i)_{i \in I}$, $\langle x_i \rangle_{i \in I} $, or $\{ x_i \}_{i \in I}$.
}{indexed_family}

\definition{Union over a Family}{
Let $(X_i)_{i \in I}$ be an \linkterm{indexed family}{indexed_family}, then $\bigcup_{i \in I} X_i := \set{x \mid \exists i \in I.x \in X_i}$
}{family_union}

\definition{Intersection over a Family}{
Let $(X_i)_{i \in I}$ be an \linkterm{indexed family}{indexed_family}, then $\bigcap_{i \in I} X_i := \set{x \mid \forall i \in I.x \in X_i}$
}{family_intersection}

\definition{$n$-fold Cartesian Product}{
$\prod_{i=1}^{n} X_i := X_1 \times \cdots \times X_n := \set{\langle x_1, \cdots, x_n \rangle \mid \forall i. 1 \leq i \leq n \Rightarrow x_i \in X_i}$ where $\langle x_1, \cdots, x_n \rangle$ is called an $n$-tuple.
}{cartesian_product_fold}

\definition{$n$-dim Cartesian Space}{
$X^n := \set{\tuple{x_1, \cdots, x_n} \mid 1 \leq i \leq n \Rightarrow x_i \in X}$ where $\tuple{x_1, \cdots, x_n}$ is called a vector.
}{cartesian_space}

\definition{Size of a Set}{
The size $\setsize{A}$ (or $\abs{A}$) of a \linkterm{set}{def:set} $A$ is the number of \linkterm{elements}{def:set} in $A$.
}{setsize}

\definition{Pairwise Disjoint}{
A \linkterm{family}{family} of \linkterm{sets}{def:set} is called \textbf{pairwise disjoint} or \textbf{mutually disjoint}, if any two of those \linkterm{sets}{def:set} are \linkterm{disjoint}{disjoint}.
}{pairwise_disjoint}

\definition{Multiset}{
A \textbf{multiset} (or \textbf{bag}) is a generalization of a \linkterm{set}{def:set} where \linkterm{elements}{def:set} can appear more than once. Formally, a multiset $\mathcal{M}$ over a domain $D$ is a pair $(D, m)$, where $m: D \to \mathbb{N}$ is a function mapping each \linkterm{element}{def:set} $x \in D$ to its \textbf{multiplicity} (the number of occurrences).
}{multiset}

\definition{Multiset Membership}{
$x \in \mathcal{M} :\equiv m(x) > 0$
}{multiset_membership}

\definition{Multiset Size}{
The size of a multiset $\mathcal{M} = (D, m)$, denoted $\setsize{\mathcal{M}}$, is the sum of the multiplicities of all its \linkterm{elements}{def:set}: $\setsize{\mathcal{M}} = \sum_{x \in D} m(x)$.
}{multiset_size}

\definition{Multiset Sum (Union)}{
The sum of two multisets $\mathcal{M}_1 = (D, m_1)$ and $\mathcal{M}_2 = (D, m_2)$, denoted $\mathcal{M}_1 \uplus \mathcal{M}_2$, is a multiset where the multiplicity of each \linkterm{element}{def:set} is the sum of its multiplicities: $m_{\uplus}(x) = m_1(x) + m_2(x)$.
}{multiset_sum}

\definition{Multiset Intersection}{
The \linkterm{intersection}{set_intersection} of two multisets $\mathcal{M}_1 = (D, m_1)$ and $\mathcal{M}_2 = (D, m_2)$, denoted $\mathcal{M}_1 \cap \mathcal{M}_2$, is a multiset where the multiplicity of each \linkterm{element}{def:set} is the minimum of its multiplicities in the two multisets: $m_{\cap}(x) = \min(m_1(x), m_2(x))$.
}{multiset_intersection}

\definition{Multiset Equality}{
$\mathcal{M}_1 \equiv \mathcal{M}_2 :\equiv \forall x \in D. m_1(x) = m_2(x)$
}{multiset_equality}

\subsection{Relations}

\definition{Relation}{
$R \subseteq A \times B$ is a (binary) relation between $A$ and $B$
}{relation}

\definition{Relation on}{
a \linkterm{relation}{relation} $R \subseteq A \times B$ where $A = B$ is called a \textit{relation on} $A$
}{relation_on}

\definition{Total}{
A \linkterm{relation}{relation} $R \subseteq A \times B$ is called \textit{total} (\textit{left total}) iff $\forall x \in A. \exists y \in B. (x,y) \in R$
}{total_relation}

\definition{Converse Relation}{
$R^{-1} \subseteq B \times A := \set{(y,x) \mid (x,y) \in R}$ is the converse \linkterm{relation}{relation} of $R$ 
}{converse_relation}

\definition{Relation Composition}{
The composition of $R \subseteq A \times B$ and $S \subseteq B \times C$ is defined as $R \circ S := \set{(a,c) \in A \times C \mid \exists b \in B. (a,b) \in R \land (b,c) \in S} $
}{relation_composition}

A \linkterm{relation on}{relation_on} $A$: $R \subseteq A \times A$ is called:
\begin{itemize}
    \item \refterm{reflexive}{reflexive} on $A$, iff $\forall a \in A. (a,a) \in R$
    \item \refterm{irreflexive}{irreflexive} on $A$, iff $\forall a \in A. (a,a) \notin R$
    \item \refterm{symmetric}{symmetric} on $A$, iff $\forall a,b \in A. (a,b) \in R \Rightarrow (b,a) \in R$
    \item \refterm{asymmetric}{asymmetric} on $A$, iff $\forall a,b \in A. (a,b) \in R \Rightarrow (b,a) \notin R$
    \item \refterm{antisymmetric}{antisymmetric} on $A$, iff $\forall a,b \in A. (a,b) \in R \land (b,a) \in R \Rightarrow a = b$
    \item \refterm{transitive}{transitive_relation} on $A$, iff $\forall a,b,c \in A. (a,b) \in R \land (b,c) \in R \Rightarrow (a,c) \in R$
    \item \refterm{equivalence relation}{equivalence_relation} on $A$, iff $R$ is \linkterm{reflexive}{reflexive} \linkterm{symmetric}{symmetric}, and \linkterm{transitive}{transitive_relation}
\end{itemize}

\definition{Equality Relation}{
The equality relation is an \linkterm{equivalence relation}{equivalence_relation} on any \linkterm{set}{def:set}.
}{equality_relation}


\definition{Divides Relation}{
The \emph{divides} \linkterm{relation on}{relation_on} the integers is defined as
$\mid \;\subseteq\; \mathbb{Z} \times \mathbb{Z},$ where $\mid \;=\;\{(a,b) \in \mathbb{Z} \times \mathbb{Z} \;\mid\; \exists k \in \mathbb{Z} : b = a \cdot k \}.$ We write $a \mid b$ to denote $(a,b) \in \mid$ (read as \textit{"$a$ divides $b$"}).
}{divides_relation}

\definition{Congruence Modulo}{
For a fixed $n \in \mathbb{N}$ with $n \geq 1$, the \emph{congruence modulo $n$} \linkterm{relation on}{relation_on} the integers is defined as  
$$\equiv_n \;\subseteq\; \mathbb{Z} \times \mathbb{Z}, \qquad 
\equiv_n \;=\;\{(a,b) \in \mathbb{Z} \times \mathbb{Z} \;\mid\; n \mid (a-b) \}.$$  
We write $a \equiv b \pmod{n}$ to denote $(a,b) \in \equiv_n$ (read as \textit{"$a$ is congruent to $b$ modulo $n$"}).
}{congruence_modulo}

\definition{Parital Ordering ($\preceq$)}{
A \linkterm{relation}{relation_on} $R \subseteq A \times A$ is called a (non-strict) \textbf{partial ordering} on $A$, iff $R$ is \linkterm{reflexive}{reflexive}, \linkterm{antisymmetric}{antisymmetric}, and \linkterm{transitive}{transitive_relation} on $A$.
}{partial_ordering}

\definition{Strict Partial Ordering ($\prec$)}{
A \linkterm{relation}{relation_on} $R \subseteq A \times A$ is called a \textbf{strict partial ordering} on $A$, iff $R$ is \linkterm{irreflexive}{irreflexive}, and \linkterm{transitive}{transitive_relation} on $A$.
}{strict_partial_ordering}


\definition{Comparable}{
In a \linkterm{non-strict partial ordering}{partial_ordering},  two elements $a,b$ are comparable if either $a \preceq b$ or $b \preceq a$. If neither holds, they are incomparable.
}{comparable}

\definition{Linear Order}{
A \linkterm{partial ordering}{partial_ordering} is called linear (or total) on $A$, iff all \linkterm{elements}{def:set} in $A$ are \linkterm{comparable}{comparable}, i.e. if $(x,y) \in R$ or $(y,x) \in R$ for all $x,y \in A$. For example, the $\leq$ \linkterm{relation}{relation_on} is a \linkterm{linear order}{linear_order} on $\mathbb{N}$. However, the \linkterm{"divides" ($\mid$) relation}{divides_relation} is a \linkterm{non-strict partial ordering}{partial_ordering} on $\mathbb{N}$ that is not \linkterm{linear}{linear_order} (e.g., neither $2 \mid 3$ nor $3 \mid 2$).
}{linear_order}

\definition{Partially Ordered Set (Poset)}{
A \textbf{Partially Ordered Set} (or \textbf{poset}) is a pair $\langle G, \preceq \rangle$ where $G$ is a \linkterm{set}{def:set} and $\preceq$ is a \linkterm{non-strict partial ordering}{partial_ordering} on $G$.
}{poset}

\definition{Least Element}{
Let $\langle G, \preceq \rangle$ be a \linkterm{poset}{poset} and $T \subseteq G$. An \linkterm{element}{def:set} $t \in T$ is the \textbf{least} (or \textbf{smallest}, \textbf{minimal}, or $\preceq$-\textbf{minimal}) element of $T$ iff $t \preceq t'$ for all $t' \in T$.
}{least_element}

\definition{Greatest Element}{
Let $\langle G, \preceq \rangle$ be a \linkterm{poset}{poset} and $T \subseteq G$. An \linkterm{element}{def:set} $t \in T$ is the \textbf{greatest} (or \textbf{largest}, \textbf{maximal}, or $\preceq$-\textbf{maximal}) element of $T$ iff $t' \preceq t$ for all $t' \in T$.
}{greatest_element}

\subsection{Functions}
\definition{Partial function}{
A \linkterm{relation}{relation} $R \subseteq X \times Y$ is a \textit{partial function} from $X$ to $Y$ ($f:X \rightharpoonup Y$) iff
$\forall x \in X, \forall y_1, y_2 \in Y. \big((x,y_1) \in R \wedge (x,y_2) \in R \Rightarrow y_1 = y_2\big)$ (i.e. there is at most one $y \in Y$ with $(x,y) \in f$)
}{partial_function}

\definition{dom, codom}{
We call $X$ the domain ($\text{dom}(f)$), and $Y$ the codomain ($\text{codom}(f)$)
}{domain_codomain}

\definition{Function Application}{
Instead of writing $(x,y) \in f$ we write $f(x)=y$
}{function_application}

\definition{Undefined}{
we call a \linkterm{partial function}{partial_function} $f:X \rightharpoonup Y$ undefined at $x \in X$, iff $\forall y \in Y. (x,y) \notin f$ ($f(x) = \bot$).
}{undefined}

\definition{Function}{
A \linkterm{partial function}{partial_function} $f:X \rightharpoonup Y$ is called a \textit{function} (or \textit{total function}) from $X$ to $Y$ iff it is a \linkterm{total relation}{total_relation}. ($\forall x \in X. \exists^1 y \in Y: (x,y) \in f$)
}{function}

\commandnote{
A \linkterm{partial function}{partial_function} guarantees uniqueness, but not existence. So each $x$ has at most one $y$ (some might have none). A \linkterm{total function}{function} guarantees both uniqueness and existence (at most and at least $\to$ exactly one)
}

A \linkterm{function}{function} $f: X \to Y$ is called
\begin{itemize}
\item \refterm{injective}{injective} iff $\forall x_1,x_2 \in X.f(x_1) = f(x_2) \Rightarrow x_1 = x_2$
\item \refterm{surjective}{surjective} iff $\forall y \in Y. \exists x \in X.f(x)=y$
\item \refterm{bijective}{bijective} iff $f$ is \linkterm{injective}{injective} and \linkterm{surjective}{surjective} 
\end{itemize}

\definition{Function Composition}{
If $f:A \to B$ and $g: B \to C$ are \linkterm{functions}{function}, then we call $g \circ f: A\to C ; x\longmapsto g(f(x))$ the composition of $g$ and $f$ (read $g$ after $f$).
}{function_composition}

\definition{Image and Preimage}{
Let $f:X \to Y$ be a \linkterm{function}{function}, $X' \subseteq X$ and $Y' \subseteq Y$, then we call
\begin{itemize}
\item $f(X'):= \set{y \in Y \mid \exists x \in X'.(x,y) \in f}$ the \textbf{image} of $X'$ under $f$,
\item $\text{Im}(f) := f(X)$ the \textbf{image} of $f$, and
\item $f^{-1}(Y') := \set{x \in X \mid \exists y \in Y'.(x,y) \in f}$ the \textbf{preimage} of $Y'$ under $f$.
\end{itemize} 
}{image_preimage}

\definition{Cardinality}{
We say that a \linkterm{set}{def:set} $A$ is \textbf{finite} and has \textbf{cardinality} $\setsize{A} \in \mathbb{N}$, iff there is a \linkterm{bijective function}{bijective} $f:A\to \set{n \in \mathbb{N} \mid n < \setsize{A}}$.
}{set_cardinality}

\definition{Countably Infinite}{
We say that a \linkterm{set}{def:set} $A$ is countably infinite, iff there is a \linkterm{bijective function}{bijective} $f: A \to \mathbb{N}$.
}{countably_infinite}

\definition{Countable}{
A \linkterm{set}{def:set} $A$ is called countable, iff it is \linkterm{finite}{set_cardinality} or \linkterm{countably infinite}{countably_infinite}.
}{countable}

\definition{Curried Function Type}{
Let $X,Y,Z$ be sets. An \textit{uncurried}  \linkterm{function}{function} is written as
\[
f : X \times Y \to Z, \quad f(x,y) = E(x,y).
\]
The same \linkterm{function}{function} can equivalently be written in \textit{curried} form as
\[
f : X \to Y \to Z, \quad f(x)(y) = E(x,y).
\]
Thus in the curried notation the \linkterm{function}{function} takes one argument at a time:
for $x \in X$, the value $f(x)$ is itself a \linkterm{function}{function} $Y \to Z$, and applying it to $y \in Y$ yields $f(x)(y) \in Z$.
}{curried_function_type}

\definition{Invertible}{
Let $A$ and $B$ be \linkterm{sets}{def:set} and \func{f}{A}{B} a \linkterm{function}{function}, then $f$ is called invertible, iff there is a \linkterm{function}{function} \func{g}{B}{A}, such that \compose{f, g} = $\operatorname{Id}_B$. $g$ is called the \linkterm{inverse function}{inverse_function} (or just \linkterm{inverse}{inverse_function}) of $f$ and is written as \inverse{f}.
}{invertible}

\subsection{Mathematical Structures}
\definition{Formulae}{
    A mathematical formula can be a \refterm{mathematical statement}{math_statement} (clause) which can be true or false (e.g. $x>5, 3+5=7$), or a \refterm{mathematical object}{math_object} (e.g. $3, n, x^2 + y^2 + z^2, \int_1^0 x^{3/2} dx$)
}{formulae}

\definition{Mathematical Structure}{
A mathematical structure combines multiple \linkterm{mathematical objects}{math_object} (the components) into a new \linkterm{object}{math_object}. The components usually have names by which they can be referenced. Given a \linkterm{definition}{definitions} of a mathematical structure $S$, we say that any \linkterm{object}{math_object} that conforms to that is an instance of $S$.
}{def:math_structure}

\definition{Group}{
A group is a \linkterm{mathematical structure}{def:math_structure} $\tuple{G, \circ, e, \inverse{.}}$ that consists of:
\begin{itemize}
    \item a base \linkterm{set}{def:set} $G$ of \linkterm{objects}{math_object},
    \item an operation $\circ : \cartprod{G,G} \to G$, such that $\forall a,b \in G. a \circ b \in G$ and $\forall a,b,c \in G. (a \circ b) \circ c = a \circ (b \circ c)$,
    \item a unit $e \in G$, such that $\forall a \in G. e \circ a = a \circ e = a$, and
    \item the \linkterm{inverse function}{inverse_function} $.^{-1} : G \to G$, such that $\forall a \in G. a \circ \inverse{a} = \inverse{a} \circ a = e$
\end{itemize}
}{group}
An example of a \linkterm{group}{group} is the \linkterm{set}{def:set} $G = \mathbb{Z}$, with the operation $\func{+}{\cartprod{\mathbb{Z},\mathbb{Z}}}{\mathbb{Z}}$; then $e = 0$ and $\inverse{.}$ is $\lambda x \in \mathbb{Z}. -x$. We write it as $\tuple{\mathbb{Z}, +, 0, -}$.

\textbf{Question: }can we do the same for multiplication where $e = 1$? If we think about it, we would be stuck on finding the $\inverse{.}$ component of the group. What can we always multiply with any integer and get $e=1$ back? Take for example $1$, we can multiply it with $\frac{1}{1}$ (great!). Take $-1$, we can multiply it with $\frac{1}{-1}$ (also great!). But take any other integer, e.g. $2$, we must multiply it with $\frac{1}{2}$ to get $1$ back, however, $\frac{1}{2} \notin \mathbb{Z}$, it is however $\in \mathbb{Q}$! The multiplicative group would only make sense iff $G = \mathbb{Q} \setminus \set{0}$. We write that as $\tuple{\mathbb{Q} \setminus \set{0}, * , 1, a \mapsto \frac{1}{a}}$.

\textbf{But }we need some multiplication \linkterm{structure}{def:math_structure} that works for $\mathbb{Z}$!

\definition{Monoid}{
A monoid is a \linkterm{mathematical structure}{def:math_structure} $\tuple{M, \circ , e}$ that consists of:
\begin{itemize}
    \item A base set $M$ of \linkterm{objects}{math_object},
    \item An operation $\circ : M \times M \to M$, such that for all $a,b \in M$, we have $a \circ b \in M$ (closure),
    \item Associativity: for all $a,b,c \in M$, $(a \circ b) \circ c = a \circ (b \circ c)$, and
    \item A unit element $e \in M$, such that for all $a \in M. e \circ a = a \circ e = a$.
\end{itemize}
}{monoid}

Hence, the \linkterm{mathematical structure}{def:math_structure} $\tuple{\mathbb{Z}, * , 1}$ is a \linkterm{monoid}{monoid} (a \linkterm{group}{group} missing an \linkterm{inverse function}{inverse_function}).


We saw that $\tuple{\mathbb{Z}, +, 0, -}$ is a \linkterm{group}{group} under addition. And $\tuple{\mathbb{Z}, *, 1}$ is a \linkterm{monoid}{monoid} under multiplication. Now, we want to do everyday arithmetics with integers; we want expressions where we have additions and multiplication (e.g. $a * (b + c)$) which evaluates to $(a * b) + (a * c)$.

For that, we need a \linkterm{mathematical structure}{def:math_structure} where both addition and multiplication live together.

\definition{Ring}{
A ring is a \linkterm{mathematical structure}{def:math_structure} $\tuple{R, + , 0 , - , * , 1}$ consisting of:
\begin{itemize}
    \item A base \linkterm{set}{def:set} $R$.
    \item An addition operation $+: R \times R \to R$ such that $\tuple{R,+,0,-}$ is a \linkterm{group}{group} (called abelian \linkterm{group}{group}).
    \item A multiplication operation $*:R \times R \to R$ such that $\tuple{R, * , 1}$ is a \linkterm{monoid}{monoid}.
    \item Distributivity: for all $a,b,c \in R, a * (b+c) = (a*b) + (a*c), (a+b)*c = (a*c) + (b*c)$
\end{itemize}
}{ring}

Hence, mixing components from the \linkterm{group}{group} $\tuple{\mathbb{Z}, +, 0, -}$ and the \linkterm{monoid}{monoid} $\tuple{\mathbb{Z}, * , 1}$ leaves us with a \linkterm{ring}{ring} $\tuple{\mathbb{Z}, +, 0, -, *, 1}$


\definition{Magma}{
A magma is a \linkterm{mathematical structure}{def:math_structure} $\tuple{M, \circ}$ consisting of:
\begin{itemize}
    \item A base \linkterm{set}{def:set} $M$, and 
    \item A binary operation $\circ: M \times M \to M$.
\end{itemize}
}{magma}
\textbf{Example: } $\tuple{\mathbb{Z}, -}$ (integers under subtraction). $\tuple{\mathbb{N}, +}$ (natural numbres under addition)

\definition{Semigroup}{
A semigroup (\linkterm{magma}{magma} with associativity) is a \linkterm{mathematical structure}{def:math_structure} $\tuple{S, \circ}$ consisting of:
\begin{itemize}
    \item A base \linkterm{set}{def:set} $S$, 
    \item A binary opertation $\circ : S \times S \to S$, and 
    \item Associativity: for all $a,b,c \in S, (a \circ b) \circ c = a \circ (b \circ c)$
\end{itemize}
}{semigroup}
\textbf{Example: } $\tuple{\mathbb{Z}, +}$ (integers under addition).

\subsection{Formal Languages and Grammars}

\definition{Alphabet}{
An alphabet is a \linkterm{finite}{set_cardinality} \linkterm{set}{def:set}; we call each element $a \in A$ a \textbf{character}, and an $n$-tuple $s \in A^n$ a \textbf{string} (of \textit{length} $n$ over $A$). We often write a string $\tuple{c_1, \cdots, c_n}$ as "$c_1 \cdots c_n$", for instance \texttt{"abc"} for $\tuple{a,b,c}$
}{alphabet}

\definition{Empty String}{
Let $A$ be an \linkterm{alphabet}{alphabet}, then $A^0 = \set{\tuple{}}$, where $\tuple{}$ is the unique $0$-tuple. We consider $\tuple{}$ as the string of length $0$ and call it the \textbf{empty string} and denote it with $\epsilon$.
}{empty_string}


\definition{String Length}{
Given a string $s$, we denote its length with $\abs{s}$.
}{string_length}

\definition{String Concatenation}{
The concatenation $\operatorname{conc}(s,t)$ of two strings $s = \tuple{s_1, \cdots, s_n} \in A^n$ and $t = \tuple{t_1,\cdots, t_m} \in A^m$ is defined as $s+t$ or simply \texttt{st}
}{concatenation_string}

\definition{Kleene Plus/Star}{
Let $A$ be an \linkterm{alphabet}{alphabet}, then we define the \linkterm{sets}{def:set}:
\begin{itemize}
    \item $A^{+} := \bigcup_{i \in \mathbb{N}^{+}} A^i$ (\textit{nonempty strings}), and
    \item $A^{*} := A^{+} \cup \set{\epsilon}$ (\textit{strings}).
\end{itemize}
}{kleene_operators}

\definition{Formal Language}{
A \linkterm{set}{def:set} $L \subseteq A^{*}$ is called a \textit{formal language} over $A$. For example, If $A = \set{a,b}$ then:
\[
A^{*} = \bigcup_{n = 0}^{\infty} A^n
\]
where $A^0 = \epsilon$, $A^1 = \set{a,b}$, $A^2 = \set{a, b, ab, ba}$, and so on ... 
\begin{align*}
    A^{*} &= \set{\epsilon, a, b, aa, ab, ba, bb, aaa, aab, aba, abb, \cdots} \\
    A^{+} &= \set{a, b, aa, ab, ba, bb, aaa, aab, aba, abb, \cdots} \\
\end{align*}
A \linkterm{formal language}{formal_language} might be $L = \set{a,b,aab,bbb, \cdots}$ 
}{formal_language}


\definition{Repeating Chars}{
We use $c^{[n]}$ for the string that consists of the character \texttt{c} repeated $n$ times. \textbf{Examples: }
\begin{itemize}
    \item Let $A = \set{a,b}$, $a^{[5]} = $ \texttt{"aaaaa"}.
    \item The \linkterm{set}{def:set} $M := \set{\text{ba}^{[n]} \mid n \in \mathbb{N}}$ of strings that start with character $b$ followd by an arbitrary numbers of a's is a \linkterm{formal language}{formal_language} over $A = \set{a,b}$
\end{itemize}
}{repeating_chars}


\commandnote{A \linkterm{formal language}{formal_language} might be infinite and even undecidable even if the \linkterm{alphabet}{alphabet} $A$ is \linkterm{finite}{set_cardinality}. For example, let $A = \set{a,b}$ then the \linkterm{formal language}{formal_language} $L = \set{a,ab,bba}$ is \linkterm{finite}{set_cardinality} but the \linkterm{formal language}{formal_language} $L = \setbuilder{a^{[n]}}{n \in \mathbb{N}}$ is infinite.}

Since we cannot list all strings in a \linkterm{formal language}{formal_language} $L$ because there are infinitely many, we need a \textbf{finite description} that can generate all strings in $L$. We need \textbf{Grammars}.

\definition{Phrase Structure Grammar}{
A phrase structure grammar (\textit{type 0 grammar, unrestricted grammar, grammar}) is a tuple $\tuple{N,\Sigma, P, S}$ where
\begin{itemize}
    \item $N$ is a \linkterm{finite}{set_cardinality} \linkterm{set}{def:set} of \textbf{nonterminal symbols},
    \item $\Sigma$ is a \linkterm{finite}{set_cardinality} \linkterm{set}{def:set} of \textbf{terminal symbols}. (members of $N \cup \Sigma$ are called symbols).
    \item $P$ is a \linkterm{finite}{set_cardinality} \linkterm{set}{def:set} of \textbf{production rules}: pairs $p := h \to b$ (also written as $h \Rightarrow b$), where $h \in (\Sigma \cup N)^{*} N (\Sigma \cup N)^{*}$ and $b \in (\Sigma \cup N)^{*}$. The string $h$ is called the \textbf{head} of $p$ and $b$ the \textbf{body}.
    \item $S \in N$ is a distinguished symbol called the \textbf{start symbol} (also \textbf{sentence symbol}).
\end{itemize}
The \linkterm{sets}{def:set} $N$ and $\Sigma$ are assumed to be \linkterm{disjoint}{disjoint}. Any word $w \in \Sigma^{*}$ is called a \textbf{terminal word}.
}{phrase_structure_grammar}
\commandnote{\linkterm{Production rules}{phrase_structure_grammar} map strings with at least one \linkterm{nonterminal}{phrase_structure_grammar} to arbitrary other strings}

\textbf{Notation: }If we have $n$ \linkterm{production rule}{phrase_structure_grammar} $h \to b_i$ sharing a head, we often write $h \to b_1 \mid \cdots \mid b_n$ instead.

\textbf{Example: }A simple \linkterm{grammar}{phrase_structure_grammar} for english sentences:
\begin{align*}
\text{S} &::= \text{NP} \text{ Vi} \\
\text{NP} &::= \text{Article} \text{ N} \\
\text{Article} &::= \text{the} \mid \text{a} \mid \text{an} \\
\text{N} &::= \text{dog} \mid \text{teacher} \mid \cdots \\
\text{Vi} &::= \text{sleeps} \mid \text{smells} \mid \cdots
\end{align*}

\definition{Lexical}{
A \linkterm{production rule}{phrase_structure_grammar} whose head is a single \linkterm{nonterminal}{phrase_structure_grammar} and whose body consists of a single \linkterm{terminal}{phrase_structure_grammar} is called \textbf{lexical} or a \textbf{lexical insertion rule}.
}{lexical_rule_grammar}

\definition{Lexicon of a Grammar}{
The \linkterm{subset}{subset} of \linkterm{lexical rules}{lexical_rule_grammar} of a \linkterm{grammar}{phrase_structure_grammar} $G$ is called the \textbf{lexicon} of $G$
}{lexicon_grammar}

\definition{Vocabulary}{
The \linkterm{set}{def:set} of body symbols are called the vocabulary (or the alphabet).
}{vocabulary_grammar}

\definition{Lexical Categories of a Grammar}{
The \linkterm{nonterminals}{phrase_structure_grammar} that appear in the heads of \linkterm{lexical}{lexical_rule_grammar} rules are called lexical categories of the \linkterm{grammar}{phrase_structure_grammar}.
}{lexical_categories_grammar}

\definition{Structural Rules}{
The non \linkterm{lexicon}{lexicon_grammar} \linkterm{production rules}{phrase_structure_grammar} are called structural.
}{structural_rules_grammar}

\definition{Phrasal categories}{
The \linkterm{nonterminals}{phrase_structure_grammar} in the heads of \linkterm{production rules}{phrase_structure_grammar} that expand into other \linkterm{nonterminals}{phrase_structure_grammar} are called phrasal (syntactic) categories.
}{phrasal_categories}

\definition{$G$-Derivation}{
Given a \linkterm{phrase structure grammar}{phrase_structure_grammar} $G := \set{N,\Sigma, P, S}$, we say $G$ \textbf{derives} $t \in (\Sigma \cup N)^{*}$ from $s \in (\Sigma \cup N)^{*}$ in one step, iff there is a \linkterm{production rule}{phrase_structure_grammar} $p \in P$ with $p = h \to b$ and there are $u,v \in (\Sigma \cup N)^{*}$, such that $s=uhv$ and $t=ubv$. We write $s \to_{G}^{p} t$ (or $s \to_{G} t$ if $p$ is clear from the context) and use $\to_{G}^{*}$ for the \linkterm{reflexive}{reflexive} \linkterm{transitive}{transitive_relation} closure of $\to_G$. We call $s \to_{G}^{*} t$ a $G$-derivation of $t$ from $s$.
}{g_derivation_grammar}

\definition{Sentential Form}{
Given a \linkterm{phrase structure grammar}{phrase_structure_grammar} $G := \set{N,\Sigma, P, S}$, we say that $s \in (\Sigma \cup N)^{*}$ is a \textbf{sentential form} of $G$, iff $S \to_{G}^{*} s$
}{sentential_form}

\definition{Sentence}{
A \linkterm{sentential form}{sentential_form} that does not contain \linkterm{nonterminals}{phrase_structure_grammar} is called a sentence of $G$, we also say that $G$ \textbf{accepts} $s$. We say that $G$ \textbf{rejects} $s$, iff it is not a sentence of $G$.
}{sentence_grammar}

\definition{Language Generation}{
The language $L(G)$ of $G$ is the \linkterm{set}{def:set} of its \linkterm{sentences}{sentence_grammar}. We say that $L(G)$ is \textbf{generated} by $G$.
}{language_generation_grammar}

\definition{Equivalent Grammars}{
We call two \linkterm{grammars}{phrase_structure_grammar} \textbf{equivalent}, iff they have the same \linkterm{languages}{language_generation_grammar}.
}{equivalent_grammars}

\definition{Universal Grammar}{
A \linkterm{grammar}{phrase_structure_grammar} $G$ is said to be \textbf{universal} if $L(G) = \Sigma^{*}$
}{universal_grammar}

\definition{Syntactic Analysis}{
Syntactic analysis (parsing / syntax analysis) is the process of analyzing a string of symbols, either in a \linkterm{formal}{formal_language} or a \linkterm{natural language}{natural_language} by means of a \linkterm{grammar}{phrase_structure_grammar}.
}{syntactic_analysis_grammar}

\commandnote{The shape of the \linkterm{grammar}{phrase_structure_grammar} determines the size of its \linkterm{language}{language_generation_grammar}}

\definition{Context-Sensitive}{
We call a \linkterm{grammar}{phrase_structure_grammar} context-sensitive (or type 1), if the bodies of \linkterm{production rules}{phrase_structure_grammar} have no less symbols than the heads.
}{contex_sensitive_grammar}

\definition{Context-Free}{
We call a \linkterm{grammar}{phrase_structure_grammar} context-free (or type 2), iff the heads have exactly one symbol.
}{contex_free_grammar}

\definition{Regular}{
We call a \linkterm{grammar}{phrase_structure_grammar} regular (or type 3, or REG), if additionally the bodies are empty or consist of a \linkterm{nonterminal}{phrase_structure_grammar}, optionally followed by a \linkterm{terminal symbol}{phrase_structure_grammar}.
}{regular_grammar}

\commandnote{
By extension, a \linkterm{formal language}{formal_language} $L$ is called \textit{context-sensitive / context-free / regular}, iff it is the \linkterm{language}{language_generation_grammar} of a respective \linkterm{grammar}{phrase_structure_grammar}. \linkterm{Context-free grammars}{contex_free_grammar} are sometimes \texttt{CFGs} and context-free languages \texttt{CFLs}.
}

\subsection{Graphs and Trees}
\definition{Undirected Graph}{
An undirected graph is a pair $\tuple{V,E}$ such that
\begin{itemize}
    \item $V$ is a \linkterm{set}{def:set} of \textbf{vertices (nodes)}, and
    \item $E \subseteq \setbuilder{\set{v, \bar{v}}}{v, \bar{v} \in V \land v \neq \bar{v}}$ is the \linkterm{set}{def:set} of its \textbf{undirected edges}. 
\end{itemize}
}{undirected_graph}

\definition{Directed Graph}{
A directed graph (digraph) is a pair $\tuple{V,E}$ such that
\begin{itemize}
    \item $V$ is a \linkterm{set}{def:set} of \textbf{vertices (nodes)}, and
    \item $E \subseteq \cartprod{V,V}$ is the \linkterm{set}{def:set} of its \textbf{directed edges}.
\end{itemize}
}{directed_graph}

\definition{Indegree}{
Given a \linkterm{directed graph}{directed_graph} $\tuple{V,E}$, the indegree $\operatorname{indeg}(v)$ of a vertex $v \in V$ is defined as $\operatorname{indeg}(v) = \setsize{\setbuilder{w}{\paren{w,v} \in E}}$.
}{indegree}

\definition{Outdegree}{
Given a \linkterm{directed graph}{directed_graph} $\tuple{V,E}$, the outdegree $\operatorname{outdeg}(v)$ (branching factor) of a vertex $v \in V$ is defined as $\operatorname{indeg}(v) = \setsize{\setbuilder{w}{\paren{v,w} \in E}}$.
}{outdegree}

\commandnote{
\linkterm{directed graphs}{directed_graph} are nothing else than \linkterm{relations}{relation}.
}

\definition{Initial vs Terminal Node}{
Let $G = \tuple{V,E}$ be a \linkterm{directed graph}{directed_graph}, then we call a node $v \in V$
\begin{itemize}
  \item \textbf{initial} (source of $G$), iff there is no $w \in V$ such that $\paren{w,v} \in E$ (no predecessor)
  \item \textbf{terminal} (sink of $G$), iff there is no $w \in V$ such that $\paren{v,w} \in E$ (no successor)
\end{itemize}
}{initial_terminal_node}

\definition{Graph Isomorphism}{
Iff we can find a \linkterm{bijection}{bijective} $\psi : V \to \bar{V}$ between two graphs $G = \tuple{V,E}$ and $\bar{G} = \tuple{\bar{V},\bar{E}}$ then we call them isomorphic. 
The \linkterm{bijection}{bijective} $\psi : V \to \bar{V}$ is defined as $(a,b) \in E \Leftrightarrow (\psi (a), \psi (b)) \in \bar{E}$ for \linkterm{directed graph}{directed_graph}. And for \linkterm{undirected graph}{undirected_graph} it is defined as $\set{a,b} \in E \Leftrightarrow \set{\psi (a), \psi (b)} \in \bar{E}$
}{graph_isomorphism}

\definition{Equivalent Graphs}{
Two graphs $G$ and $\bar{G}$ are \textbf{equivalent} iff there is an \linkterm{isomorphism}{graph_isomorphism} $\psi$ between $G$ and $\bar{G}$.
}{equivalent_graphs}

\definition{Labeled Graph}{
A labeled graph $G$ is a quadruple $\tuple{V,E,L,l}$ where $\tuple{V,E}$ is a graph and $\pfunc{l}{\union{V,E}}{L}$ is a \linkterm{partial function}{partial_function} into a \linkterm{set}{def:set} $L$ of labels.
}{labeled_graph}

\definition{Paths in Graphs}{
Given a graph $G:=\tuple{V,E}$ we call a $n+1$-tuple $p=\tuple{v_0, \cdots, v_n} \in V^{n+1}$ a \textbf{path} in $G$ iff $(v_{i-1}, v_i) \in E$ for all $1 \leq i \leq n$ and $n>0$.
\begin{itemize}
\item We say that $v_i$ are nodes on $p$ and that $v_0$ and $v_n$ are \textbf{linked} by $p$.
\item $v_0$ and $v_n$ are called the \textbf{start} and \textbf{end} of $p$ (write $\operatorname{start}(p)$ and $\operatorname{end}(p)$), the other $v_i$ are called \textbf{inner nodes} of $p$.
\item $n$ is called the \textbf{length} of $p$ (write $\operatorname{len}(p)$).
\item We denote the \linkterm{set}{def:set} of paths in $G$ with $\Pi(G)$. 
\end{itemize}
}{path_graph}

\definition{Cyclic Graphs}{
Given a \linkterm{directed graph}{directed_graph} $G = \tuple{V,E}$, a \linkterm{path}{path_graph} $p$ is called \textbf{cyclic} iff $\operatorname{start}(p) = \operatorname{end}(p)$. A cycle $\tuple{v_0, \cdots, v_n}$ is called \textbf{simple}, iff $v_i \neq v_j$ for $1 \leq i$, $j \leq n$ with $i \neq j$ (all inner nodes are distinct).
}{cyclic_graphs}

\definition{DAG}{
A \linkterm{directed graph}{directed_graph} with no \linkterm{cycles}{cyclic_graphs} is called \textbf{directed acyclic graph (DAG)}.
}{dag}

\definition{Node Depth}{
Let $G = \tuple{V,E}$ be a \linkterm{directed graph}{directed_graph}, then the depth $\operatorname{dp}(v)$ of a vertex $v \in V$ is defined to be $0$, iff $v$ is a source of $G$ and the \linkterm{supremum}{supremum_infimum} $\operatorname{sup}(\setbuilder{\operatorname{len}(p)}{\operatorname{indeg}(\operatorname{start}(p))=0 \land \operatorname{end}(p)=v})$ otherwise, i.e. the length of the longest \linkterm{path}{path_graph} from a source of $G$ to $v$ (can be infinite).
}{depth_node}

\definition{Graph Depth}{
Given a \linkterm{directed graph}{directed_graph} $G = \tuple{V,E}$, the \textbf{depth} ($\operatorname{dp}(G)$) of $G$ is defined as the \linkterm{supremum}{supremum_infimum} $\operatorname{sup}(\setbuilder{\operatorname{len}(p)}{p \in \Pi(G)})$, i.e. the maximal path length in $G$.
}{depth_graph}

\definition{Tree}{
A tree is a \linkterm{DAG}{dag} $G = \tuple{V,E}$ such that
\begin{itemize}
  \item There is exactly one \linkterm{initial node}{initial_terminal_node} $v_r \in V$ (called the \textbf{root})
  \item All nodes but the root have \linkterm{indegree}{indegree} of $1$.
\end{itemize}
We call $v$ the \textbf{parent} of $w$, iff $(v,w) \in E$ ($w$ is a child of $v$). We call a node $v$ a \textbf{leaf} of $G$, iff it is \linkterm{terminal}{initial_terminal_node}, i.e. if it does not have children.
}{tree}

\commandnote{
For any node $v \in V$ except the root $v_r$, there is exactly one \linkterm{path}{path_graph} $p \in \Pi(G)$ with $\operatorname{start}(p) = v_r$ and $\operatorname{end}(p)=v$.
}